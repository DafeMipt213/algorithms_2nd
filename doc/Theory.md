# Теория по алгоритмам <!-- omit in $to$ c -->

## Содержание

- [Теория по алгоритмам ](#теория-по-алгоритмам-)
  - [Содержание](#содержание)
  - [1. Обходы графа](#1-обходы-графа)
    - [1.1. Ориентированный граф, псевдограф. Неориентированный граф, псевдограф. Связность в неориентированном графе, компоненты связности. Слабая и сильная связность в ориентированном графе. Компоненты слабой, сильной связности](#11-ориентированный-граф-псевдограф-неориентированный-граф-псевдограф-связность-в-неориентированном-графе-компоненты-связности-слабая-и-сильная-связность-в-ориентированном-графе-компоненты-слабой-сильной-связности)
      - [Ориентированный граф](#ориентированный-граф)
      - [Неориентированный граф](#неориентированный-граф)
    - [1.2. Обход в глубину. Цвета вершин. Времена входа и выхода. Лемма о белых путях (с доказательством)](#12-обход-в-глубину-цвета-вершин-времена-входа-и-выхода-лемма-о-белых-путях-с-доказательством)
      - [Обход в глубину](#обход-в-глубину)
      - [Лемма о белых путях](#лемма-о-белых-путях)
    - [1.3. Проверка связности неориентированного графа. Поиск цикла в неориентированном и ориентированном графе. Топологическая сортировка](#13-проверка-связности-неориентированного-графа-поиск-цикла-в-неориентированном-и-ориентированном-графе-топологическая-сортировка)
      - [Проверка связности неориентированного графа](#проверка-связности-неориентированного-графа)
      - [Поиск цикла в неориентированном и ориентированном графе](#поиск-цикла-в-неориентированном-и-ориентированном-графе)
      - [Топологическая сортировка](#топологическая-сортировка)
    - [1.4. Нахождение компонент сильной связности. Алгоритм Косарайю с доказательством корректности(концепция). Алгоритм Тарьяна без доказательства корректности](#14-нахождение-компонент-сильной-связности-алгоритм-косарайю-с-доказательством-корректностиконцепция-алгоритм-тарьяна-без-доказательства-корректности)
      - [Нахождение компонент сильной связности](#нахождение-компонент-сильной-связности)
      - [Алгоритм Косарайю с доказательством корректности(концепция)](#алгоритм-косарайю-с-доказательством-корректностиконцепция)
      - [Алгоритм Тарьяна без доказательства корректности](#алгоритм-тарьяна-без-доказательства-корректности)
    - [1.5. Компоненты реберной двусвязности. Мосты. Поиск мостов](#15-компоненты-реберной-двусвязности-мосты-поиск-мостов)
      - [Компоненты реберной двусвязности](#компоненты-реберной-двусвязности)
      - [Мосты](#мосты)
      - [Поиск мостов](#поиск-мостов)
    - [1.6. Компоненты вершинной двусвязности. Точки сочленения. Поиск точек сочленения](#16-компоненты-вершинной-двусвязности-точки-сочленения-поиск-точек-сочленения)
      - [Компоненты вершинной двусвязности](#компоненты-вершинной-двусвязности)
      - [Точки сочленения](#точки-сочленения)
      - [Поиск точек сочленения](#поиск-точек-сочленения)
    - [1.7. Волновой алгоритм. Обход в ширину (применение очереди в волновом алгоритме)](#17-волновой-алгоритм-обход-в-ширину-применение-очереди-в-волновом-алгоритме)
      - [Волновой алгоритм](#волновой-алгоритм)
      - [Обход в ширину (применение очереди в волновом алгоритме)](#обход-в-ширину-применение-очереди-в-волновом-алгоритме)
    - [1.8. Критерий существования Эйлерова пути и цикла в ориентированном и неориентированном графе. Поиск эйлерова пути и цикла](#18-критерий-существования-эйлерова-пути-и-цикла-в-ориентированном-и-неориентированном-графе-поиск-эйлерова-пути-и-цикла)
      - [Критерий существования Эйлерова пути и цикла в неориентированном графе](#критерий-существования-эйлерова-пути-и-цикла-в-неориентированном-графе)
      - [Критерий существования Эйлерова пути и цикла в ориентированном графе](#критерий-существования-эйлерова-пути-и-цикла-в-ориентированном-графе)
      - [Поиск эйлерова пути и цикла](#поиск-эйлерова-пути-и-цикла)
  - [2. Планарность графа](#2-планарность-графа)
    - [2.1. Формула Эйлера. Теорема Портнягина-Куратовского. Теорема Вагнера](#21-формула-эйлера-теорема-портнягина-куратовского-теорема-вагнера)
      - [Формула Эйлера](#формула-эйлера)
      - [Теорема Портнягина-Куратовского](#теорема-портнягина-куратовского)
      - [Теорема Вагнера](#теорема-вагнера)
    - [2.2. Гамма алгоритм. Контактная вершина](#22-гамма-алгоритм-контактная-вершина)
      - [Гамма алгоритм](#гамма-алгоритм)
    - [2.3. Теорема о корректности Гамма алгоритма. Асимптотика алгоритма](#23-теорема-о-корректности-гамма-алгоритма-асимптотика-алгоритма)
      - [Теорема о корректности Гамма алгоритма](#теорема-о-корректности-гамма-алгоритма)
  - [3. Кратчайшие пути во взвешенном графе](#3-кратчайшие-пути-во-взвешенном-графе)
    - [3.1. Алгоритм Дейкстры. Доказательство корректности(с доказательством). Оценка времени работы. Дерево кратчайших путей](#31-алгоритм-дейкстры-доказательство-корректностис-доказательством-оценка-времени-работы-дерево-кратчайших-путей)
      - [Алгоритм Дейкстры](#алгоритм-дейкстры)
      - [Доказательство корректности](#доказательство-корректности)
      - [Оценка времени работы](#оценка-времени-работы)
      - [Дерево кратчайших путей](#дерево-кратчайших-путей)
    - [3.2. Потенциалы. Условие применимости алгоритма Дейкстры для измененных длин ребер. Потенциал $\\pi(v) = \\rho(v, t)$](#32-потенциалы-условие-применимости-алгоритма-дейкстры-для-измененных-длин-ребер-потенциал-piv--rhov-t)
      - [Потенциалы](#потенциалы)
      - [Условие применимости алгоритма Дейкстры для измененных длин ребер](#условие-применимости-алгоритма-дейкстры-для-измененных-длин-ребер)
      - [Потенциал $\\pi(v) = \\rho(v, t)$](#потенциал-piv--rhov-t)
    - [3.3. Алгоритм A\*. Условие монотонности на эвристику. Примеры эвристик](#33-алгоритм-a-условие-монотонности-на-эвристику-примеры-эвристик)
      - [Алгоритм A\*](#алгоритм-a)
      - [Примеры эвристик](#примеры-эвристик)
    - [3.4. Алгоритм Форда-Беллмана. Хранение в матрице: $D\_{vk}$ равно длине кратчайшего пути до вершины $v$ за ровно $k$ ребер (не более $k$ ребер). Доказательство корректности (полное). Оценка времени работы](#34-алгоритм-форда-беллмана-хранение-в-матрице-d_vk-равно-длине-кратчайшего-пути-до-вершины-v-за-ровно-k-ребер-не-более-k-ребер-доказательство-корректности-полное-оценка-времени-работы)
      - [Доказательство корректности(полное)](#доказательство-корректностиполное)
      - [Оценка времени работы](#оценка-времени-работы-1)
    - [3.5. Восстановление пути. Детектирование цикла отрицательного веса. Поиск самого цикла](#35-восстановление-пути-детектирование-цикла-отрицательного-веса-поиск-самого-цикла)
      - [Восстановление пути](#восстановление-пути)
      - [Детектирование цикла отрицательного веса](#детектирование-цикла-отрицательного-веса)
      - [Поиск самого цикла](#поиск-самого-цикла)
    - [3.6. Нахождение кратчайших путей с учетом циклов отрицательного веса](#36-нахождение-кратчайших-путей-с-учетом-циклов-отрицательного-веса)
    - [3.7. Алгоритм Флойда. Доказательство (концепция). Восстановление пути](#37-алгоритм-флойда-доказательство-концепция-восстановление-пути)
      - [Алгоритм Флойда](#алгоритм-флойда)
      - [Доказательство (концепция)](#доказательство-концепция)
      - [Восстановление пути](#восстановление-пути-1)
    - [3.8. Нахождение цикла отрицательного веса](#38-нахождение-цикла-отрицательного-веса)
    - [3.9. Алгоритм Джонсона. Добавление фиктивного корня и фиктивных ребер для запуска алгоритма Форда-Беллмана](#39-алгоритм-джонсона-добавление-фиктивного-корня-и-фиктивных-ребер-для-запуска-алгоритма-форда-беллмана)
      - [Алгоритм Джонсона](#алгоритм-джонсона)
      - [Добавление фиктивного корня и фиктивных ребер для запуска алгоритма Форда-Беллмана](#добавление-фиктивного-корня-и-фиктивных-ребер-для-запуска-алгоритма-форда-беллмана)

## 1. Обходы графа

### 1.1. Ориентированный граф, псевдограф. Неориентированный граф, псевдограф. Связность в неориентированном графе, компоненты связности. Слабая и сильная связность в ориентированном графе. Компоненты слабой, сильной связности

#### Ориентированный граф

> **Ориентированным графом** (англ. *directed graph*) $G$ называется пара $G = (V, E)$, где $V$ — множество вершин (англ. vertices), а $E \subset V \times V$ — множество рёбер.

> **Псевдограф(*мультиорграф*)** — это ориентированный граф, в котором разрешены кратные дуги, то есть дуги, имеющие те же начальные и конечные вершины.

**Псевдографом** $G$ называется упорядоченная пара $G := (V, A)$, в которой $V$ — множество вершин, $A$ — мультимножество упорядоченных пар вершин. Элементы этого множества называются дугами.

> Ориентированный граф называется **слабо связным**, если соответствующий неориентированный граф является связным;

> Ориентированный граф называется **сильно связным**, если всякая вершина $v$ достижима из любой другой вершины $v$;

> **Компонентой сильной связности** ориентированного графа называется максимальный по включению сильно связный подграф. Другими словами, это подграф, любые две вершины которого принадлежат какому-либо циклу, и содержащий все такие циклы для своих вершин.

> **Компонентой слабой связности** ориентированного графа называют его максимальный слабо связный подграф.

#### Неориентированный граф

> **Неориентированным графом** (англ. *undirected graph*) $G$ называется пара $G = (V, E)$, где $V$ — множество вершин, а $E \subset {{v,u} : v,u \in V}$ — множество рёбер.

Формально, псевдографом (*мультифграфом*) $G$ называется упорядоченная пара $G := (V, E)$, в которой $V$ — множество вершин, $E$ — мультимножество неупорядоченных пар вершин. Элементы этого множества называются рёбрами.

> Неориентированный граф называется *связным*, если все его вершины достижимы из некоторой вершины (эквивалентно, из любой его вершины).

> **Компонентой связности** неориентированного графа называется максимальный по включению связный подграф

### 1.2. Обход в глубину. Цвета вершин. Времена входа и выхода. Лемма о белых путях (с доказательством)

#### Обход в глубину

> **Обход в глубину** (поиск в глубину, англ. *Depth-First Search*, *DFS*) — один из основных методов обхода графа, часто используемый для проверки связности, поиска цикла и компонент сильной связности и для топологической сортировки.

```c++
#include <vector>

std::vector<std::vector<int>> graph; // граф
int vertex_count; // число вершин

std::vector<int> color; // цвет вершины (0, 1, или 2)

std::vector<int> time_in, time_out; // "времена" захода и выхода из вершины
int dfs_timer = 0; // "таймер" для определения времён

void dfs (int vertex) {
  time_in[vertex] = dfs_timer++;
  color[vertex] = 1;
  for (int u : graph[vertex])
    if (color[u] == 0)
      dfs(u);
  color[v] = 2;
  time_out[v] = dfs_timer++;
}
```

#### Лемма о белых путях

> Лемма: Не существует такого момента выполнения поиска в глубину, в который бы существовало ребро из черной вершины в белую.

**Доказательство**: Пусть в процессе выполнения процедуры DFS нашлось ребро из черной вершины  $v$ в белую вершину u. Рассмотрим момент времени, когда мы запустили DFS(v). В этот момент вершина  $v$ была перекрашена из белого в серый, а вершина u была белая. Далее в ходе выполнения алгоритма будет запущен DFS(u), поскольку обход в глубину обязан посетить все белые вершины, в которые есть ребро из v. По алгоритму вершина  $v$ будет покрашена в черный цвет тогда, когда завершится обход всех вершин, достижимых из нее по одному ребру, кроме тех, что были рассмотрены раньше нее. Таким образом, вершина  $v$ может стать черной только тогда, когда DFS выйдет из вершины u, и она будет покрашена в черный цвет. Получаем противоречие.

### 1.3. Проверка связности неориентированного графа. Поиск цикла в неориентированном и ориентированном графе. Топологическая сортировка

#### Проверка связности неориентированного графа

Небольшая модификация алгоритма обхода в глубину, в которой будем возвращать количество посещенных вершин. Запустим такой **DFS** от некоторой вершины графа $G$, если его результат равен $|V|$, то мы побывали во всех вершинах графа, а следовательно он связен, иначе какие-то вершины остались непосещенными. Работает алгоритм за $O(|V|+|E|)$

```c++
std::vector<std::vector<int>> graph; // граф

// visited — массив цветов вершин  
int dfs(int vertex, std::vector<bool> visited):              
  int visitedVertices = 1
  visited[vertex] = true // помечаем вершину как пройденную
  for (auto u : graph[vertex]) // проходим по смежным с u вершинам
    // проверяем, не находились ли мы ранее в выбранной вершине
    if (!visited[v])
      visitedVertices += dfs(v, visited)
    return visitedVertices
```

#### Поиск цикла в неориентированном и ориентированном графе

*Условие:*

Пусть дан ориентированный или неориентированный граф без петель и кратных рёбер. Требуется проверить, является ли он ациклическим, а если не является, то найти любой цикл.

*Решение:*

Произведём серию поисков в глубину в графе. Т.е. из каждой вершины, в которую мы ещё ни разу не приходили, запустим поиск в глубину, который при входе в вершину будет красить её в серый цвет, а при выходе - в чёрный. И если поиск в глубину пытается пойти в серую вершину, то это означает, что мы нашли цикл (если граф неориентированный, то случаи, когда поиск в глубину из какой-то вершины пытается пойти в предка, не считаются).

```c++
#include <iostream>
#include <vector>

int n;
std::vector<vector<int>> graph;
std::vector<int> color;
std::vector<int> parent;
int cycle_start, cycle_end;

bool dfs(int vertex) {
  color[vertex] = 1;
  for (size_t i = 0; i < graph[vertex].size(); ++i) {
    int $to$  = graph[vertex][i];
    if (color[to] == 0) {
      parent[to] = vertex;
      if (dfs(to)) return true;
    }
    else if (color[to] == 1) {
      cycle_end = vertex;
      cycle_start = $to$ ;
      return true;
    }
  }
  color[vertex] = 2;
  return false;
}

int main() {
  // чтение графа

  parent.assign(n, -1);
  color.assign(n, 0);
  cycle_start = -1;
  for (int i = 0; i < n; ++i)
    if (dfs(i))
      break;

  if (cycle_st == -1)
    std::cout << "Acyclic" << "\n";
  else {
    std::cout << "Cyclic" << "\n";
    std::vector<int> cycle;
    cycle.push_back(cycle_start);
    for (int vertex = cycle_end; vertex != cycle_start; vertex = parent[vertex])
      cycle.push_back(vertex);
    cycle.push_back(cycle_start);
    reverse(cycle.begin(), cycle.end());
    for (size_t i = 0; i < cycle.size(); ++i)
      std::cout << cycle[i]+1 << " ";
  }
}
```

#### Топологическая сортировка

*Условие:*
Дан ориентированный граф с n вершинами и m рёбрами. Требуется перенумеровать его вершины таким образом, чтобы каждое рёбро вело из вершины с меньшим номером в вершину с большим. Иными словами, требуется найти перестановку вершин (топологический порядок), соответствующую порядку, задаваемому всеми рёбрами графа.
(**Топологическая сортировка** - упорядочивание вершин ациклического ориентированного графа согласно частичному порядку, заданному ребрами орграфа на множестве его вершин.)
Топологическая сортировка может быть не единственной (например, если граф — пустой; или если есть три такие вершины `a`, `b`, `c`, что из `a` есть пути в `b` и в `c`, но ни из `b` в `c`, ни из `c` в `b` добраться нельзя).

Топологической сортировки может не существовать вовсе — если граф содержит циклы (поскольку при этом возникает противоречие: есть путь и из одной вершины в другую, и наоборот).

```c++
#include <vector>

int n; // число вершин
std::vector<std::vector<int>> graph; // граф
std::vector<bool> visited;
std::vector<int> $to$ pological_sort;

void dfs (int vertex) {
  visited[vertex] = true;
  for (int u : graph[vertex])
    if (!visited[u] == 0)
      dfs(u);
  $to$ pological_sort.push_back(vertex);
}

void $to$ pological_sort() {
  visited.assign(n, false);
  answer.clear();
  for (int i = 0; i < n; ++i)
    if (!visited[i])
      dfs(i);
  reverse(answer.begin(), answer.end());
}
```

### 1.4. Нахождение компонент сильной связности. Алгоритм Косарайю с доказательством корректности(концепция). Алгоритм Тарьяна без доказательства корректности

#### Нахождение компонент сильной связности

*Условие:*

Дан ориентированный граф $G$, множество вершин которого $V$ и множество рёбер — $E$. Петли и кратные рёбра допускаются. Обозначим через $n$ количество вершин графа, через $m$ — количество рёбер.

*Решение:*

Напомним, что **компонентой сильной связности** (*strongly connected component*) называется такое (максимальное по включению) подмножество вершин $C4, что любые две вершины этого подмножества достижимы друг из друга, т.е. для любых $u,  $v$ \in C: u \rightarrow v,  $v$ \rightarrow u$, где символом $\rightarrow$ здесь и далее мы будем обозначать достижимость, т.е. существование пути из первой вершины во вторую. Понятно, что компоненты сильной связности для данного графа не пересекаются, т.е. фактически это разбиение всех вершин графа. Отсюда логично определение конденсации G как графа, получаемого из данного графа сжатием каждой компоненты сильной связности в одну вершину. Каждой вершине графа конденсации соответствует компонента сильной связности графа G, а ориентированное ребро между двумя вершинами $C_i$ и $C_j$ графа конденсации проводится, если найдётся пара вершин u из $C_i$, из $C_j$, между которыми существовало ребро в исходном графе, т.е. $(u, v)$ из $E$.

Важнейшим свойством графа конденсации является то, что он ацикличен. Действительно, предположим, что $C \rightarrow C'$, докажем, что $C' \mapsto C$. Из определения конденсации получаем, что найдутся две вершины $u$ из $C$ и $v$ из $C'$, что $u \rightarrow v$. Доказывать будем от противного, т.е. предположим, что $C' \rightarrow C$, тогда найдутся две вершины $u'$ из $C$ и $v'$ из $C'$, что $v' \rightarrow u'$. Но т.к. $u$ и $u'$ находятся в одной компоненте сильной связности, то между ними есть путь; аналогично для $v$ и $v'$. В итоге, объединяя пути, получаем, что $v \rightarrow u$, и одновременно $u \rightarrow v$. Следовательно, $u$ и $v$ должны принадлежать одной компоненте сильной связности, т.е. получили противоречие, что и требовалось доказать

#### Алгоритм Косарайю с доказательством корректности(концепция)

Алгоритм Косарайю предназначен для поиска компонент сильной связности в ориентированном графе и состоит из трёх шагов:

1. Выполнить поиск в глубину (DFS), пока не будут «помечены» все вершины. Вершина считается «помеченной», когда ей присвоено время выхода из рекурсии (см. основные понятия).

2. Инвертировать исходный граф

3. Выполнить DFS в порядке убывания пометок вершин.

Полученные деревья каждого такта DFS последнего шага являются компонентами сильной связности

**Доказательство корректности алгоритма:**

Немного уточним, что требуется доказать: Вершины $u$ и $v$ сильно связаны $\Leftrightarrow$ после выполнения алгоритма они принадлежат одному дереву такта DFS.

Если вершины u и  $v$ были сильно связаны в графе $G$, на третьем этапе будет найден путь из одной вершины в другую (по Лемме (Инвертирование рёбер цикла не влияет на его цикличность)), так как на первом шаге был найден путь $u \rightarrow v$, а на третьем - путь $v \rightarrow u$. Это означает, что по окончании алгоритма обе вершины лежат в одном дереве.

Вершины $u$ и $v$ лежат в одном и том же дереве поиска в глубину на третьем шаге алгоритма. Значит, они обе достижимы из корня $r$ этого дерева.

Вершина $r$ была рассмотрена на 3 шаге раньше всех, значит время выхода из неё на 1 шаге больше, чем время выхода из вершин $u$ и $v$. Из этого мы получаем 2 случая:

Обе эти вершины были достижимы из $r$ в исходном графе. Это означает сильную связность вершин $u$ и $r$ и сильную связность вершин $v$ и $r$ (по Лемме 3). Склеивая пути мы получаем связность вершин $u$ и $v$ (по Лемме 1)

Хотя бы одна вершина не достижима из $r$ в исходном графе, например $v$. Значит и $r$ была не достижима из $v$ в исходном графе, так как время выхода из $r$ — больше (если бы она была достижима, то время выхода из $v$ было бы больше, чем из $r$, просмотрите ещё раз первый шаг примера). Значит между этими вершинами нет пути (ни в исходном, ни в инвертированном графах), но последнего быть не может, потому что по условию  $v$ достижима из r на 3 шаге (в инвертированном графе)

Значит, из случая 1 и не существования случая 2 получаем, что вершины $u$ и $v$ сильно связаны в обоих графах

#### Алгоритм Тарьяна без доказательства корректности

Основой для алгоритма является структура данных "Система непересекающихся множеств", которая и была изобретена Тарьяном (Tarjan).

Алгоритм фактически представляет собой обход в глубину из корня дерева, в процессе которого постепенно находятся ответы на запросы. А именно, ответ на запрос $(v, u)$ находится, когда обход в глубину находится в вершине $u$, а вершина $v$ уже была посещена, или наоборот.

Итак, пусть обход в глубину находится в вершине $v$ (и уже были выполнены переходы в её сыновей), и оказалось, что для какого-то запроса $(v, u)$ вершина u уже была посещена обходом в глубину. Научимся тогда находить $LCA$ этих двух вершин.

Заметим, что $LCA(v, u)$ является либо самой вершиной $v$, либо одним из её предков. Получается, нам надо найти самую нижнюю вершину среди предков $v$ (включая её саму), для которой вершина u является потомком. Заметим, что при фиксированном $v$ по такому признаку (т.е. какой наименьший предок $v$ является и предком какой-то вершины) вершины дерева дерева распадаются на совокупность непересекающихся классов. Для каждого предка $p \neq v$ вершины $v$ её класс содержит саму эту вершину, а также все поддеревья с корнями в тех её сыновьях, которые лежат "слева" от пути до $v$ (т.е. которые были обработаны ранее, чем была достигнута $v$).

Нам надо научиться эффективно поддерживать все эти классы, для чего мы и применим структуру данных "Система непересекающихся множеств". Каждому классу будет соответствовать в этой структуре множество, причём для представителя этого множества мы определим величину **ANCESTOR** — ту вершину $p$, которая и образует этот класс.

Рассмотрим подробно реализацию обхода в глубину. Пусть мы стоим в некоторой вершине $v$. Поместим её в отдельный класс в структуре непересекающихся множеств, **ANCESTOR**[v] = $v$. Как обычно в обходе в глубину, перебираем все исходящие рёбра $(v, $to$ )$. Для каждого такого $to$ мы сначала должны вызвать обход в глубину из этой вершины, а потом добавить эту вершину со всем её поддеревом в класс вершины $v$. Это реализуется операцией **Union** структуры данных "система непересекающихся множеств", с последующей установкой **ANCESTOR** = $v$ для представителя множества (т.к. после объединения представитель класса мог измениться). Наконец, после обработки всех рёбер мы перебираем все запросы вида $(v, u)$, и если u была помечена как посещённая обходом в глубину, то ответом на этот запрос будет вершина $LCA(v,u)$ = **ANCESTOR**[FindSet(u)]. Нетрудно заметить, что для каждого запроса это условие (что одна вершина запроса является текущей, а другая была посещена ранее) выполнится ровно один раз.

Оценим асимптотику. Она складывается из нескольких частей. Во-первых, это асимптотика обхода в глубину, которая в данном случае составляет $O(n)$. Во-вторых, это операции по объединению множеств, которые в сумме для всех разумных n затрачивают $O(n)$ операций. В-третьих, это для каждого запроса проверка условия (два раза на запрос) и определение результата (один раз на запрос), каждое, опять же, для всех разумных n выполняется за $O(1)$. Итоговая асимптотика получается $O(n + m)$, что означает для достаточно больших $m$ $(n = O(m))$ ответ за $O(1)$ на один запрос

### 1.5. Компоненты реберной двусвязности. Мосты. Поиск мостов

#### Компоненты реберной двусвязности

> **Компонентами рёберной двусвязности** (англ. *costal doubly-linked components*) графа называют его подграфы, множества вершин которых - классы эквивалентности рёберной двусвязности, а множества рёбер - множества ребер из соответствующих классов эквивалентности.

#### Мосты

> **Мостом** называется такое ребро, удаление которого делает граф несвязным (или, точнее, увеличивает число компонент связности).

#### Поиск мостов

- Алгоритм:
    Запустим обход в глубину из произвольной вершины графа; обозначим её через **root**. Заметим следующий факт (который несложно доказать):

    Пусть мы находимся в обходе в глубину, просматривая сейчас все рёбра из вершины $v$. Тогда, если текущее ребро $(v,to)$ таково, что из вершины $to$ и из любого её потомка в дереве обхода в глубину нет обратного ребра в вершину  $v$ или какого-либо её предка, то это ребро является мостом. В противном случае оно мостом не является. (В самом деле, мы этим условием проверяем, нет ли другого пути из  $v$ в $to$ , кроме как спуск по ребру $(v,to)$ дерева обхода в глубину.)
    Теперь осталось научиться проверять этот факт для каждой вершины эффективно. Для этого воспользуемся "временами входа в вершину", вычисляемыми алгоритмом поиска в глубину.

    Итак, пусть $tin[v]$ — это время захода поиска в глубину в вершину $v$. Теперь введём массив $fup[v]$, который и позволит нам отвечать на вышеописанные запросы. Время $fup[v]$ равно минимуму из времени захода в саму вершину $tin[v]$, времён захода в каждую вершину $p$, являющуюся концом некоторого обратного ребра $(v, p)$, а также из всех значений $fup[to]$ для каждой вершины $to$ , являющейся непосредственным сыном $v$ в дереве поиска:

    $fup[v] = \min(tin[v], tin[p], fup(to))$ $(v, p)$ - back edge, $(v, to)$ - tree edge (здесь "back edge" — обратное ребро, "tree edge" — ребро дерева)

    Тогда, из вершины  $v$ или её потомка есть обратное ребро в её предка тогда и только тогда, когда найдётся такой сын $to$ , что $fup[to] \leq tin[v]$. (Если $fup[to] = tin[v]$, то это означает, что найдётся обратное ребро, приходящее точно в $v$; если же $fup[to] < tin[v]$, то это означает наличие обратного ребра в какого-либо предка вершины $v$.)

    Таким образом, если для текущего ребра $(v,to)$ (принадлежащего дереву поиска) выполняется $fup[to] > tin[v]$, то это ребро является мостом; в противном случае оно мостом не является.

### 1.6. Компоненты вершинной двусвязности. Точки сочленения. Поиск точек сочленения

#### Компоненты вершинной двусвязности

> **Компонентами вершинной двусвязности** графа, называют его подграфы, множества ребер которых — классы эквивалентности вершинной двусвязности, а множества вершин — множества всевозможных концов ребер из соответствующих классов.

#### Точки сочленения

> **Точкой сочленения** называется вершина, при удалении которой связный неориентированный граф становится несвязным.

#### Поиск точек сочленения

- Алгоритм:
    Запустим обход в глубину из произвольной вершины графа; обозначим её через $root$. Заметим следующий факт (который несложно доказать):

    Пусть мы находимся в обходе в глубину, просматривая сейчас все рёбра из вершины  $v \neq root$. Тогда, если текущее ребро $(v, to)$ таково, что из вершины $to$  и из любого её потомка в дереве обхода в глубину нет обратного ребра в какого-либо предка вершины v, то вершина  $v$ является точкой сочленения. В противном случае, т.е. если обход в глубину просмотрел все рёбра из вершины $v$, и не нашёл удовлетворяющего вышеописанным условиям ребра, то вершина $v$ не является точкой сочленения. (В самом деле, мы этим условием проверяем, нет ли другого пути из  $v$ в $to$ )
    Рассмотрим теперь оставшийся случай:  $v = root$. Тогда эта вершина является точкой сочленения тогда и только тогда, когда эта вершина имеет более одного сына в дереве обхода в глубину. (В самом деле, это означает, что, пройдя из $root$ по произвольному ребру, мы не смогли обойти весь граф, откуда сразу следует, что $root$ — точка сочленения).
    (Ср. формулировку этого критерия с формулировкой критерия для алгоритма поиска мостов.)

    Теперь осталось научиться проверять этот факт для каждой вершины эффективно. Для этого воспользуемся "временами входа в вершину", вычисляемыми алгоритмом поиска в глубину.

    Итак, пусть $tin[v]$ — это время захода поиска в глубину в вершину v. Теперь введём массив $fup[v]$, который и позволит нам отвечать на вышеописанные запросы. Время $fup[v]$ равно минимуму из времени захода в саму вершину $tin[v]$, времён захода в каждую вершину p, являющуюся концом некоторого обратного ребра $(v, p)$, а также из всех значений $fup[to]$ для каждой вершины $to$ , являющейся непосредственным сыном  $v$ в дереве поиска:

    $fup[v] = \min(tin[v], tin[p], fup(to))$ $(v, p)$ - back edge, $(v, to)$ - tree edge (здесь "back edge" — обратное ребро, "tree edge" — ребро дерева)

    Тогда, из вершины  $v$ или её потомка есть обратное ребро в её предка тогда и только тогда, когда найдётся такой сын $to$ , что $fup[to] < tin[v]$.

    Таким образом, если для текущего ребра $(v,to)$ (принадлежащего дереву поиска) выполняется $fup[to] \geq tin[v]$, то вершина  $v$ является точкой сочленения. Для начальной вершины  $v = root$ критерий другой: для этой вершины надо посчитать число непосредственных сыновей в дереве обхода в глубину.

### 1.7. Волновой алгоритм. Обход в ширину (применение очереди в волновом алгоритме)

#### Волновой алгоритм

> **Алгоритм волновой трассировки** (*волновой алгоритм*) — алгоритм поиска пути, алгоритм поиска кратчайшего пути на планарном графе. Принадлежит к алгоритмам, основанным на методах поиска в ширину.

Алгоритм предназначен для поиска кратчайшего пути от стартовой ячейки к конечной ячейке, если это возможно, либо, при отсутствии пути, выдать сообщение о непроходимости.

Работа алгоритма включает в себя три этапа: инициализацию, распространение волны и восстановление пути.

Инициализация

```c
Пометить стартовую ячейку 
d := 0 
```

Распространение волны

```c
ЦИКЛ
  ДЛЯ каждой ячейки loc, помеченной числом d
    пометить все соседние свободные непомеченные ячейки числом d + 1
  КЦ
  d := d + 1
ПОКА (финишная ячейка не помечена) И (есть возможность распространения волны) 
```

Восстановление пути

```c
ЕСЛИ финишная ячейка помечена
ТО
  перейти в финишную ячейку
  ЦИКЛ
    выбрать среди соседних ячейку, помеченную числом на 1 меньше числа в текущей ячейке
    перейти в выбранную ячейку и добавить её к пути
  ПОКА текущая ячейка — не стартовая
  ВОЗВРАТ путь найден
ИНАЧЕ
  ВОЗВРАТ путь не найден
```

#### Обход в ширину (применение очереди в волновом алгоритме)

> **Поиск в ширину** (англ. *breadth-first search*) — один из основных алгоритмов на графах, позволяющий находить все кратчайшие пути от заданной вершины и решать многие другие задачи.

- Описание алгоритма
    На вход алгоритма подаётся невзвешенный граф и номер стартовой вершины $s$. Граф может быть как ориентированным, так и неориентированным — для алгоритма это не важно.

    Основную идею алгоритма можно понимать как процесс «поджигания» графа: на нулевом шаге мы поджигаем вершину $s$, а на каждом следующем шаге огонь с каждой уже горящей вершины перекидывается на всех её соседей, в конечном счете поджигая весь граф.

    Если моделировать этот процесс, то за каждую итерацию алгоритма будет происходить расширение «кольца огня» в ширину на единицу. Номер шага, на котором вершина  $v$ начинает гореть, в точности равен длине её минимального пути из вершины s.

```c++
std::vector<int> graph;

void bfs(int s) {
    std::queue<int> queue;
    queue.push(s);
    
    std::vector<int> depth(n, -1), parent(n);
    depth[s] = 0;
    
    while (!queue.empty()) {
        int vertex = queue.front();
        queue.pop();
        for (int u : g[vertex]) {
            if (depth[u] == -1) {
                queue.push(u);
                depth[u] = depth[vertex] + 1;
                parent[u] = vertex;
            }
        }
    }
} 
```

Теперь, чтобы восстановить кратчайший путь до какой-то вершины v, это можно сделать через массив p:

```c++
while (v != s) {
    std::cout << v << endl;
    v = p[v];
}
```

Обратим внимание, что путь выведется в обратном порядке.

### 1.8. Критерий существования Эйлерова пути и цикла в ориентированном и неориентированном графе. Поиск эйлерова пути и цикла

#### Критерий существования Эйлерова пути и цикла в неориентированном графе

- Согласно теореме, доказанной Эйлером, эйлеров цикл существует тогда и только тогда, когда
    1. Граф связный или будет являться связным, если удалить из него все изолированные вершины.
    2. В нём отсутствуют вершины нечётной степени.

- Эйлеров путь в графе существует тогда и только тогда, когда
    1. Граф связный
    2. Содержит не более двух вершин нечётной степени. Ввиду леммы о рукопожатиях, число вершин с нечётной степенью должно быть чётным. А значит эйлеров путь существует только тогда, когда это число равно нулю или двум. Причём, когда оно равно нулю, эйлеров путь вырождается в эйлеров цикл.

#### Критерий существования Эйлерова пути и цикла в ориентированном графе

- В ориентированном графе $G = (V, E)$ существует эйлеров цикл тогда и только тогда, когда:
    1. Входная степень любой вершины равна ее выходной степени.
    2. Все компоненты слабой связности кроме, может быть одной, не содержат ребер.
- В ориентированном графе $G = (V, E)$ существует эйлеров путь если:
    1. Входная степень любой вершины равна ее выходной степени, кроме двух вершин графа, для одной из которых (deg+) − (deg−) = 1, а для другой (deg+) − (deg−) = −1 .
    2. Все компоненты слабой связности кроме, может быть одной, не содержат ребер.

#### Поиск эйлерова пути и цикла

- Поиск эйлерова пути в графе
    Можно всегда свести задачу поиска эйлерова пути к задаче поиска эйлерова цикла. Действительно, предположим, что эйлерова цикла не существует, а эйлеров путь существует. Тогда в графе будет ровно 2 вершины нечётной степени. Соединим эти вершины ребром, и получим граф, в котором все вершины чётной степени, и эйлеров цикл в нём существует. Найдём в этом графе эйлеров цикл (алгоритмом, описанным ниже), а затем удалим из ответа несуществующее ребро.

- Поиск эйлерова цикла в графе
    Будем рассматривать самый общий случай — случай ориентированного мультиграфа, возможно, с петлями. Также мы предполагаем, что эйлеров цикл в графе существует (и состоит хотя бы из одной вершины). Для поиска эйлерова цикла воспользуемся тем, что эйлеров цикл — это объединение всех простых циклов графа. Следовательно, наша задача — эффективно найти все циклы и эффективно объединить их в один.

    Реализовать это можно, например, так, рекурсивно:

    ```c
    procedure find_all_cycles (v)
    var массив cycles
    1. пока есть цикл, проходящий через v, находим его
        добавляем все вершины найденного цикла в массив cycles (сохраняя порядок обхода)
        удаляем цикл из графа
    2. идем по элементам массива cycles
        каждый элемент cycles[i] добавляем к ответу
        из каждого элемента рекурсивно вызываем себя: find_all_cycles (cycles[i])
    ```

    Достаточно вызвать эту процедуру из любой вершины графа, и она найдёт все циклы в графе, удалит их из графа и объединит их в один эйлеров цикл.
    Для поиска цикла на шаге 1 используем поиск в глубину.
    Сложность полученного алгоритма — $O(|E|)$, то есть линейная относительно количества рёбер в данном графе

## 2. Планарность графа

### 2.1. Формула Эйлера. Теорема Портнягина-Куратовского. Теорема Вагнера

#### Формула Эйлера

Для произвольного плоского связного графа $G$ с $V$ вершинами, $E$ ребрами и $F$ гранями справедливо следующее соотношение: $V − E + F = 2$.

#### Теорема Портнягина-Куратовского

Теорема Понтрягина — Куратовского, или теорема Куратовского, — теорема в теории графов, дающая необходимое и достаточное условие планарности графа. Имеет эквивалентную формулировку на языке миноров, так называемою теорему Вагнера.

Теорема утверждает, что графы $K_5$ (полный граф на 5 вершинах) и $K_{3,3}$ (полный двудольный граф имеющий по 3 вершины в каждой доле) являются единственными минимальными непланарными графами.

#### Теорема Вагнера

Теорема Вагнера — характеризация планарных графов тесно связанная с теоремой Понтрягина — Куратовского.

Теорема утверждает, что конечный граф является планарным тогда и только тогда, когда его миноры не включают ни $K_5$ (полный граф с пятью вершинами), ни $K_{3,3}$ (коммунальный граф, полный двудольный граф с тремя вершинами в каждой доле).

### 2.2. Гамма алгоритм. Контактная вершина

#### Гамма алгоритм

- Чтобы проверить планарность графа и произвести его плоскую укладку, удобно пользоваться гамма-алгоритмом.
- Определения:
    1. Сегмент графа $Г$ относительно подграфа $H$ — компонента связности графа $G \setminus H$.
    2. *Допустимая грань сегмента* — грань графа $H$, содержащая все контактные вершины.
    3. **Контактная вершина** сегмента $S$ графа $G$ подграфа $H$ — любая вершина в $S$ и в $H$.
    4. *Гамма-цепь сегмента* — любая цепь без повторов вершин, содержащих ровно две контактные вершины — начало и конец.
- Алгоритм:
    1. Уложить на плоскость любой цикл $H$ графа $G$ без повторов вершин.
    2. Построить все сегменты $S_1$ , $...$ , $S_k$ графа $G$ по $H$.
    3. Если есть сегмент $S_i$ c одной допустимой гранью — выбрать его.
    4. Если все сегменты имеют несколько дополнительных граней — выбрать любой.
    5. Выбрать произвольную гамма-цепь сегмента и уложить её в допустимую грань.
    6. Перейти к шагу (2), добавив гамма-цепь к графу $H$.

### 2.3. Теорема о корректности Гамма алгоритма. Асимптотика алгоритма

#### Теорема о корректности Гамма алгоритма

- Теорема: Гамма-алгоритм корректен, то есть если $G$ — планарный граф, то результатом каждого шага гамма-алгоритма является частичная укладка $G'$.
- Доказательство:
    Докажем индукцией по числу шагов.

    База индукции: полученный на этапе инициализации граф $G_0$ является простым циклом, он будет присутствовать в любой укладке графа $G$. Таким образом, $G_0$  является частичной укладкой.

    Шаг индукции: пусть граф $G_{k−1}$, полученный на $k−1$-м шаге работы алгоритма, является частичной укладкой. Докажем, что граф $G_k = G_{k−1} \cup L_k$, полученный на $k$-м шаге присоединением цепи $L_k$, также является частичной укладкой.

    Заметим, что на текущем шаге нет такого сегмента $S$  относительно $G_{k−1}$, для которого бы выполнялось равенство $Γ(S) = \varnothing$, так как в противном случае существовала бы цепь этого сегмента, контактные вершины которой принадлежали бы разным граням и укладка которой была бы невозможна. Следовательно, нельзя было бы уложить $S$,что противоречит тому, что $G$ — планарный граф. Значит, мы можем рассматривать только следующие два случая:
    1. Существует сегмент $S$ для которого есть единственная вмещающая грань $Γ$, то есть $|Γ(S)| = 1$. Так как только грани $Γ$ принадлежат все контактные вершины $S$, то укладка этого сегмента в эту грань неизбежна. Это значит, что помещая любую цепь $L \subset S$, снова получим частичную укладку графа.
    
    2. Для любого сегмента $S$ $|Γ(S)| \geq 2$. Построим граф $A(G'k−1)$, который по лемме 2 является двудольным. Рассмотрим его связную компоненту $K$, которая содержит не менее двух вершин. Граф $K$ также является двудольным. По лемме 1 для любого сегмента $S \in K$  справедливо $Γ(S)={Γ1, Γ2}$. Так как граф $K$ двудольный, то мы можем по очереди помещать сегменты $K$ в разные грани, причем конфликтующих сегментов не возникнет в силу четности всех циклов в графе. Результатом будет частичная укладка графа.

    Таким образом, на каждом шаге мы получаем частичную укладку графа, что доказывает корректность гамма-алгоритма.

**Асимптотика алгоритма - $O(n^3)$.**

## 3. Кратчайшие пути во взвешенном графе

### 3.1. Алгоритм Дейкстры. Доказательство корректности(с доказательством). Оценка времени работы. Дерево кратчайших путей

#### Алгоритм Дейкстры

**Алгоритм Дейкстры** (англ. *Dijkstra’s algorithm*) — алгоритм на графах, изобретённый нидерландским учёным Эдсгером Дейкстрой в 1959 году. Находит кратчайшие пути от одной из вершин графа до всех остальных. Алгоритм работает только для графов без рёбер отрицательного веса.

```c
func dijkstra(s):
    for $v \in V$
        d[v] = $ \infinity $
        used[v] = false
    d[s] = 0
    for $i \in V$
        v = null
        for $j \in V$    // найдём вершину с минимальным расстоянием
            if !used[j] and (v == null or d[j] < d[v])
                v = j
        if d[v] == $\infinity$
            break
        used[v] = true
        for e : исходящие из v рёбра     // произведём релаксацию по всем рёбрам, исходящим из v
            if d[v] + e.len < d[e.to]
                d[e.to] = d[v] + e.len
```

#### Доказательство корректности

- Пусть $G=(V,E)$ — ориентированный взвешенный граф, вес рёбер которого неотрицателен, s — стартовая вершина. Тогда после выполнения алгоритма Дейкстры $d(u)=\rho(s, u)$ для всех $u$, где $\rho (s,u)$ — длина кратчайшего пути из вершины $s$ в вершину $u$.

Докажем по индукции, что в момент посещения любой вершины $u$, $d(u)= \rho (s,u)$.

На первом шаге выбирается $s$, для неё выполнено: $d(s) = \rho (s,s) = 0$. Пусть для $n$ первых шагов алгоритм сработал верно и на $n+1$ шагу выбрана вершина $u$. Докажем, что в этот момент $d(u)= \rho (s,u)$. Для начала отметим, что для любой вершины $v$, всегда выполняется $d(v) \geq \rho (s,v)$ (алгоритм не может найти путь короче, чем кратчайший из всех существующих). Пусть $P$ — кратчайший путь из $s$ в $u$, $v$ — первая непосещённая вершина на $P$, $z$ — предшествующая ей (следовательно, посещённая). Поскольку путь $P$ кратчайший, его часть, ведущая из $s$ через $z$ в $v$, тоже кратчайшая, следовательно $\rho(s,v)= \rho(s,z)+w(zv)$. По предположению индукции, в момент посещения вершины $z$ выполнялось $d(z)= \rho (s,z)$, следовательно, вершина $v$ тогда получила метку не больше чем $d(z) + w(zv) = \rho (s,z) + w(zv) = \rho(s,v)$, следовательно, $d(v)=\rho(s,v)$. С другой стороны, поскольку сейчас мы выбрали вершину $u$, её метка минимальна среди непосещённых, то есть $d(u) \leq d(v) = \rho (s,v) \leq \rho (s,u)$, где второе неравенсто верно из-за ранее упомянутого определения вершины $v$ в качестве первой непосещённой вершины на $P$, то есть вес пути до промежуточной вершины не превосходит веса пути до конечной вершины вследствие неотрицательности весовой функции. Комбинируя это с $d(u) \geq \rho(s,u)$, имеем $d(u)=\rho(s,u)$, что и требовалось доказать. Поскольку алгоритм заканчивает работу, когда все вершины посещены, в этот момент $d(u)= \rho (s,u)$ для всех $u$.

#### Оценка времени работы

- Если $m = n ^ 2$(граф плотный), то $O(n^2)$.
- Если $m = n$(граф разреженный), то $O(m log n)$.

#### Дерево кратчайших путей

Решение ряда прикладных задач сводится к нахождению дерева кратчайших путей с корнем в заданной вершине $s$. Такое дерево дает кратчайшие $(s, v)$-пути от заданной вершины $s$ до любой вершины $v$ орграфа $G = (V, Е)$. Если веса всех дуг орграфа $G$ неотрицательны, то дерево кратчайших путей можно построить с помощью алгоритма Дейкстры.

### 3.2. Потенциалы. Условие применимости алгоритма Дейкстры для измененных длин ребер. Потенциал $\pi(v) = \rho(v, t)$

#### Потенциалы

Пусть дана транспортная сеть $G(V,E)$, где $V$ — множество вершин графа, а $E$ — множество рёбер. Введем в каждой вершине потенциал $\pi(v)$. Тогда потенциальный вес (то есть стоимость) ребра $(u,v)$ определяется как $w_p(u,v)=w(u,v)+\pi(u)−\pi(v)$

#### Условие применимости алгоритма Дейкстры для измененных длин ребер

Можно применять, когда нет отрицательных циклов (следует из курса дискретной математики 1 курс 2 семестр)

#### Потенциал $\pi(v) = \rho(v, t)$

### 3.3. Алгоритм A*. Условие монотонности на эвристику. Примеры эвристик

#### Алгоритм A*

Алгоритм A* - алгоритм поиска по первому наилучшему совпадению на графе, который находит маршрут с наименьшей стоимостью от одной вершины (начальной) к другой (целевой, конечной).

Порядок обхода вершин определяется эвристической функцией «расстояние + стоимость» (обычно обозначаемой как $f(x)$). Эта функция — сумма двух других: функции стоимости достижения рассматриваемой вершины (x) из начальной (обычно обозначается как $g(x)$ и может быть как эвристической, так и нет), и функции эвристической оценки расстояния от рассматриваемой вершины к конечной (обозначается как $h(x)$).

1. Функция $h(x)$ должна быть *допустимой эвристической оценкой*, то есть не должна переоценивать расстояния к целевой вершине. Например, для задачи маршрутизации $h(x)$ может представлять собой расстояние до цели по прямой линии, так как это физически наименьшее возможное расстояние между двумя точками.
2. Более сильное условие — функция $h(v)$ должна быть **монотонной**. (Эвристическая функция $h(v)$ называетя **монотонной** (или преемственной), если для любой вершины $v_1$ и ее потомка $v_2$ разность $h(v_1)$ и $h(v_2)$ не превышает фактического веса ребра $c(v_1, v_2)$ от $v_1$ до $v_2$, а эвристическая оценка целевого состояния равна нулю.)

```c
function A*(start, goal, f)
     % множество уже пройденных вершин
     var closed := the empty set
     % множество частных решений
     var open := make_queue(f)
     enqueue(open, path(start))
     while open is not empty
         var p := remove_first(open)
         var x := the last node of p
         if x in closed
            continue
         if x = goal
            return $\rho$
         add(closed, x)
         % добавляем смежные вершины
         foreach y in successors(x)
            enqueue(open, add_to_path(p, y))
     return failure
```

#### Примеры эвристик

- Если мы можем перемещаться в четырех направлениях, то в качестве эвристики стоит выбрать манхэттенское расстояние $h(v)=|v.x−goal.x|+|v.y−goal.y|$.
- Расстояние Чебышева применяется, когда к четырем направлениям добавляются диагонали: $h(v)=max(|v.x−goal.x|,|v.y−goal.y|)$.
- Если передвижение не ограничено сеткой, то можно использовать евклидово расстояние по прямой: $h(v)=((v.x−goal.x) ^ 2+(v.y−goal.y)^2) ^ {1/2}$.

### 3.4. Алгоритм Форда-Беллмана. Хранение в матрице: $D_{vk}$ равно длине кратчайшего пути до вершины $v$ за ровно $k$ ребер (не более $k$ ребер). Доказательство корректности (полное). Оценка времени работы

Количество путей длины k рёбер можно найти с помощью метода динамического программирования. Пусть $d[k][u]$ — количество путей длины k рёбер, заканчивающихся в вершине u. Тогда $d[k][u]= \Sigma v: v u \in E(d[k−1][v])$.

Аналогично посчитаем пути кратчайшей длины. Пусть $s$ — стартовая вершина. Тогда $d[k][u]=\min v: v u \in E(d[k−1][v]+w(u,v))$, при этом $d[0][s]=0$, а $d[0][u]=+\infty$

Если существует кратчайший путь от s до t, то $\rho(s,t)=\min d[k][t](k=0..n−1)$

Пусть кратчайший путь состоит из $k$ ребер, тогда корректность формулы следует из динамики, приведенной ниже.

```c++
for k = 0 to |V|−2       // вершины нумеруются с единицы
    for v∈V
       for (u,v)∈E
          d[k + 1][v] = min(d[k + 1][v], d[k][u] + ω(u,v))     // ω(u,v) — вес ребра uv
```


```c++
bool fordBellman(s):
    for v∈V
        d[v] = 1
    d[s] = 0
    for i = 0 to |V|−1
        for (u,v)∈E
            if d[v] > d[u] + ω(u,v)     // ω(u,v) — вес ребра uv
                d[v] = d[u] + ω(u,v)
    for (u,v)∈E
        if d[v] > d[u] + ω(u,v)
            return false
    return true
```

#### Доказательство корректности(полное)

Во-первых, сразу заметим, что для недостижимых из $v$ вершин алгоритм отработает корректно: для них метка $d[]$ так и останется равной бесконечности (т.к. алгоритм Форда-Беллмана найдёт какие-то пути до всех достижимых из $s$ вершин, а релаксация во всех остальных вершинах не произойдёт ни разу).

Докажем теперь следующее утверждение: после выполнения $i$ фаз алгоритм Форда-Беллмана корректно находит все кратчайшие пути, длина которых (по числу рёбер) не превосходит $i$.

Иными словами, для любой вершины $a$ обозначим через $k$ число рёбер в кратчайшем пути до неё (если таких путей несколько, можно взять любой). Тогда это утверждение говорит о том, что после $k$ фаз этот кратчайший путь будет найден гарантированно.

**Доказательство.**

Рассмотрим произвольную вершину a, до которой существует путь из стартовой вершины v, и рассмотрим кратчайший путь до неё: $(p_0=v, p_1, ..., p_k=a)$. Перед первой фазой кратчайший путь до вершины $p_0=v$ найден корректно. Во время первой фазы ребро $(p_0,p_1)$ было просмотрено алгоритмом Форда-Беллмана, следовательно, расстояние до вершины $p_1$ было корректно посчитано после первой фазы. Повторяя эти утверждения k раз, получаем, что после $k$-й фазы расстояние до вершины $p_k=a$ посчитано корректно, что и требовалось доказать.

Последнее, что надо заметить — это то, что любой кратчайший путь не может иметь более $n-1$ ребра. Следовательно, алгоритму достаточно произвести только $n-1$ фазу. После этого ни одна релаксация гарантированно не может завершиться улучшением расстояния до какой-то вершины.

#### Оценка времени работы

Инициализация занимает $\theta(V)$ времени, каждый из $|V|−1$ проходов требует $\theta(E)$ времени, обход по всем ребрам для проверки наличия отрицательного цикла занимает $O(E)$ времени. Значит алгоритм Беллмана-Форда работает за $O(VE)$ времени.

### 3.5. Восстановление пути. Детектирование цикла отрицательного веса. Поиск самого цикла

#### Восстановление пути

```c++
void solve() {
  vector<int> d (n, INF);
  d[v] = 0;
  vector<int> p (n, -1);
  for (;;) {
    bool any = false;
    for (int j=0; j<m; ++j)
      if (d[e[j].a] < INF)
        if (d[e[j].b] > d[e[j].a] + e[j].cost) {
          d[e[j].b] = d[e[j].a] + e[j].cost;
          p[e[j].b] = e[j].a;
          any = true;
        }
    if (!any)  break;
  }
 
  if (d[t] == INF)
    cout << "No path from " << v << " to " << t << ".";
  else {
    vector<int> path;
    for (int cur=t; cur!=-1; cur=p[cur])
      path.push_back (cur);
    reverse (path.begin(), path.end());
 
    cout << "Path from " << v << " to " << t << ": ";
    for (size_t i=0; i<path.size(); ++i)
      cout << path[i] << ' ';
  }
}
```

Здесь мы сначала проходимся по предкам, начиная с вершины t, и сохраняем весь пройденный путь в списке $\rm path$. В этом списке получается кратчайший путь от v до t, но в обратном порядке, поэтому мы вызываем $\rm reverse$ от него и затем выводим.

#### Детектирование цикла отрицательного веса

Пусть $G=(V,E)$ — взвешенный ориентированный граф, $s$ — стартовая вершина. Если граф $G$ не содержит отрицательных циклов, достижимых из вершины $s$, то алгоритм возвращает $\rm true$ и для всех $v \in V$ $d[v]= \delta (s,v)$. Если граф $G$ содержит отрицательные циклы, достижимые из вершины $s$, то алгоритм возвращает $\rm false$.

#### Поиск самого цикла

Приведенная выше реализация позволяет определить наличие в графе цикла отрицательного веса. Чтобы найти сам цикл, достаточно хранить вершины, из которых производится релаксация.

Если после $|V|−1$ итерации найдется вершина $v$, расстояние до которой можно уменьшить, то эта вершина либо лежит на каком-нибудь цикле отрицательного веса, либо достижима из него. Чтобы найти вершину, которая лежит на цикле, можно $|V|−1$ раз пройти назад по предкам из вершины $v$. Так как наибольшая длина пути в графе из $|V|$ вершин равна $|V|−1$, то полученная вершина u будет гарантированно лежать на отрицательном цикле.

Зная, что вершина u лежит на цикле отрицательного веса, можно восстанавливать путь по сохраненным вершинам до тех пор, пока не встретится та же вершина u. Это обязательно произойдет, так как в цикле отрицательного веса релаксации происходят по кругу.

### 3.6. Нахождение кратчайших путей с учетом циклов отрицательного веса

Заметим, что updated_vertices на $|V|$-м шаге содержит два типа вершин: те, которые лежат на цикле отрицательного веса и те, которые сами достижимы из какого-то цикла отрицательного веса. При этом из доказательства леммы выше мы знаем, что от каждого (!) цикла отрицательного веса в множестве будет хотя бы по одному представителю. Из этих двух наблюдений следует корректность и полнота следующего алгоритма:

Запускаем Форда-Беллмана на $|V|$ шагов. Если на последнем шаге до вершины расстояние не поменялось, то оно и кратчайшее. Если поменялось, то до неё и до всех вершин, достижимых из неё, расстояние от стартовой вершины равно минус бесконечности. Чтобы найти все вершины с расстоянием минус бесконечность, достаточно запустить dfs из всех вершин, расстояние до которых уменьшилось на последней итерации алгоритма.

### 3.7. Алгоритм Флойда. Доказательство (концепция). Восстановление пути

#### Алгоритм Флойда

> **Алгоритм Флойда** (*алгоритм Флойда–Уоршелла*) — алгоритм нахождения длин кратчайших путей между всеми парами вершин во взвешенном ориентированном графе. Работает корректно, если в графе нет циклов отрицательной величины, а в случае, когда такой цикл есть, позволяет найти хотя бы один такой цикл.

Ключевая идея алгоритма — разбиение процесса поиска кратчайших путей на фазы.

Перед $k$-ой фазой $(k = 1 ... n)$ считается, что в матрице расстояний $d[][]$ сохранены длины таких кратчайших путей, которые содержат в качестве внутренних вершин только вершины из множества ${1, 2, ..., k-1}$ (вершины графа мы нумеруем, начиная с единицы).

Иными словами, перед $k$-ой фазой величина $d[i][j]$ равна длине кратчайшего пути из вершины $i$ в вершину $j$, если этому пути разрешается заходить только в вершины с номерами, меньшими k (начало и конец пути не считаются).

Легко убедиться, что чтобы это свойство выполнилось для первой фазы, достаточно в матрицу расстояний $d[][]$ записать матрицу смежности графа: $d[i][j] = g[i][j]$ — стоимости ребра из вершины $i$ в вершину $j$. При этом, если между какими-то вершинами ребра нет, то записать следует величину "бесконечность". Из вершины в саму себя всегда следует записывать величину 0, это критично для алгоритма.

Пусть теперь мы находимся на $k$-ой фазе, и хотим пересчитать матрицу $d[][]$ таким образом, чтобы она соответствовала требованиям уже для $k+1$-ой фазы. Зафиксируем какие-то вершины $i$ и $j$. У нас возникает два принципиально разных случая:

Кратчайший путь из вершины $i$ в вершину $j$, которому разрешено дополнительно проходить через вершины ${1, 2, ..., k}$, совпадает с кратчайшим путём, которому разрешено проходить через вершины множества ${1, 2, ..., k-1}$.
В этом случае величина $d[i][j]$ не изменится при переходе с $k$-ой на $k+1$-ую фазу.

"Новый" кратчайший путь стал лучше "старого" пути. Это означает, что "новый" кратчайший путь проходит через вершину $k$. Сразу отметим, что мы не потеряем общности, рассматривая далее только простые пути (т.е. пути, не проходящие по какой-то вершине дважды).

Тогда заметим, что если мы разобьём этот "новый" путь вершиной $k$ на две половинки (одна идущая $i \rightarrow k$, а другая — $k \rightarrow j$), то каждая из этих половинок уже не заходит в вершину $k$. Но тогда получается, что длина каждой из этих половинок была посчитана ещё на $k-1$-ой фазе или ещё раньше, и нам достаточно взять просто сумму $d[i][k] + d[k][j]$, она и даст длину "нового" кратчайшего пути.

Объединяя эти два случая, получаем, что на $k$-ой фазе требуется пересчитать длины кратчайших путей между всеми парами вершин $i$ и $j$ следующим образом:

```c++
new_d[i][j] = min(d[i][j], d[i][k] + d[k][j]);
```

Таким образом, вся работа, которую требуется произвести на $k$-ой фазе — это перебрать все пары вершин и пересчитать длину кратчайшего пути между ними. В результате после выполнения $n$-ой фазы в матрице расстояний $d[i][j]$ будет записана длина кратчайшего пути между $i$ и $j$, либо бесконечность, если пути между этими вершинами не существует.

Последнее замечание, которое следует сделать, — то, что можно не создавать отдельную матрицу $new_d[][]$ для временной матрицы кратчайших путей на $k$-ой фазе: все изменения можно делать сразу в матрице $d[][]$. В самом деле, если мы улучшили (уменьшили) какое-то значение в матрице расстояний, мы не могли ухудшить тем самым длину кратчайшего пути для каких-то других пар вершин, обработанных позднее.

#### Доказательство (концепция)

Доказательство "правильности" работы этого алгоритма также очевидно и выполняется с помощью математической индукции по $k$, показывая, что на $k$-й итерации вершина $k$ включается в путь только тогда, когда новый путь короче старого.

#### Восстановление пути

Легко поддерживать дополнительную информацию — так называемых "предков", по которым можно будет восстанавливать сам кратчайший путь между любыми двумя заданными вершинами в виде последовательности вершин.

Для этого достаточно кроме матрицы расстояний $d[][]$ поддерживать также матрицу предков $p[][]$, которая для каждой пары вершин будет содержать номер фазы, на которой было получено кратчайшее расстояние между ними. Понятно, что этот номер фазы является не чем иным, как "средней" вершиной искомого кратчайшего пути, и теперь нам просто надо найти кратчайший путь между вершинами $i$ и $p[i][j]$, а также между $p[i][j]$ и $j$. Отсюда получается простой рекурсивный алгоритм восстановления кратчайшего пути.

### 3.8. Нахождение цикла отрицательного веса

Если в графе есть циклы отрицательного веса, то формально алгоритм Флойда-Уоршелла неприменим к такому графу.

На самом же деле, для тех пар вершин $i$ и $j$, между которыми нельзя зайти в цикл отрицательного вес, алгоритм отработает корректно.

Для тех же пар вершин, ответа для которых не существует (по причине наличия отрицательного цикла на пути между ними), алгоритм Флойда найдёт в качестве ответа какое-то число (возможно, сильно отрицательное, но не обязательно). Тем не менее, можно улучшить алгоритм Флойда, чтобы он аккуратно обрабатывал такие пары вершин и выводил для них, например, - бесконечность.

Для этого можно сделать, например, следующий критерий "не существования пути". Итак, пусть на данном графе отработал обычный алгоритм Флойда. Тогда между вершинами $i$ и $j$ не существует кратчайшего пути тогда и только тогда, когда найдётся такая вершина $t$, достижимая из $i$ и из которой достижима $j$, для которой выполняется $d[t][t] < 0$.

Кроме того, при использовании алгоритма Флойда для графов с отрицательными циклами следует помнить, что возникающие в процессе работы расстояния могут сильно уходить в минус, экспоненциально с каждой фазой. Поэтому следует принять меры против целочисленного переполнения, ограничив все расстояния снизу какой-нибудь величиной (например, - Бесконечность).

### 3.9. Алгоритм Джонсона. Добавление фиктивного корня и фиктивных ребер для запуска алгоритма Форда-Беллмана

#### Алгоритм Джонсона

> Алгоритм Джонсона позволяет найти кратчайшие пути между всеми парами вершин в течение времени $O(V \cdot 2 \log(V) + VE)$. Для разреженных графов этот алгоритм ведет себя асимптотически быстрее алгоритма Флойда. Этот алгоритм либо возвращает матрицу кратчайших расстояний между всеми парами вершин, либо сообщение о том, что в графе существует цикл отрицательной длины.

В этом алгоритме используется метод изменения веса (англ. reweighting). Суть его заключается в том, что для заданного графа G строится новая весовая функция $\omega_\varphi$, неотрицательная для всех ребер графа G и сохраняющая кратчайшие пути. Такая весовая функция строится с помощью так называемой потенциальной функции.

Пусть $\varphi: V \rightarrow R$ — произвольное отображение из множества вершин в вещественные числа. Тогда новой весовой функцией будет $\omega_\varphi(u,v)=\varphi(u,v)+\varphi(u)−\varphi(v)$.

Такая потенциальная функция строится добавлем фиктивной вершины $s$ в $G$, из которой проведены ориентированные ребра нулевого веса во все остальные вершины графа, и запуском алгоритма Форда-Беллмана из нее ($\varphi(v)$ будет равно длине кратчайшего пути из $s$ в $v$). На этом же этапе мы сможем обнаружить наличие отрицательного цикла в графе.

Теперь, когда мы знаем, что веса всех ребер неотрицательны, и кратчайшие пути сохранятся, можно запустить алгоритм Дейкстры из каждой вершины и таким образом найти кратчайшие расстояния между всеми парами вершин.

#### Добавление фиктивного корня и фиктивных ребер для запуска алгоритма Форда-Беллмана

Как в случае применения алгоритма Беллмана-Форда для обнаружения отрицательных циклов, существуют два способа сделать вес каждого ребра неотрицательным в произвольной сети без отрицательных циклов. Либо можно начать с истока в каждом сильно связном компоненте, либо добавить фиктивную вершину с ребром нулевой длины в каждую вершину сети. В любом случае получится остовный лес кратчайших путей, которым можно воспользоваться для присвоения весов вершинам (вес пути из корня в данную вершину в ее SPT).
